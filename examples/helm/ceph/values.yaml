images:
  daemon: docker.io/ceph/daemon:latest
  exporter: digitalocean/ceph_exporter:1.0.0
  ceph_init: docker.io/kollakube/centos-binary-ceph-init-k8s:4.0.0

image_policy:
  pull: Always

# As per: https://github.com/ceph/ceph-container/blob/main/src/daemon/debug.sh
# Available options are: verbose,fstree and stayalive.
# They can be used altogether like this: DEBUG=verbose,fstree=http://myfstree,stayalive
debug_level: verbose

labels:
  node_selector_key: ceph-storage
  node_selector_value: enabled

service:
  mon:
    name: ceph-mon
    port: 6789
  rgw:
    name: ceph-rgw
    port: 8080
  exporter:
    name: ceph-exporter
    port: 9128

#When undefined here, it both networks default to: 10.244.0.0/16 (flannel)
network:
  cluster: 10.192.0.0/10
  public: 10.192.0.0/10

secrets:
  keyrings:
    mon: ceph-mon-keyring
    mds: ceph-bootstrap-mds-keyring
    osd: ceph-bootstrap-osd-keyring
    rgw: ceph-bootstrap-rgw-keyring
    admin: ceph-client-admin-keyring

ceph:
  cluster: ceph
  enabled:
    mds: true
    rgw: true
    exporter: true
  storage:
    osd_directory: /var/lib/ceph-helm/ceph/osd
    var_directory: /var/lib/ceph-helm/ceph/ceph
  config:
    global:
      cephx: true
      cephx_require_signatures: false
      cephx_cluster_require_signatures: true
      cephx_service_require_signatures: false
      # auth
      max_open_files: 131072
      osd_pool_default_pg_num: 128
      osd_pool_default_pgp_num: 128
      osd_pool_default_size: 3
      osd_pool_default_min_size: 1
      mon_osd_full_ratio: .95
      mon_osd_nearfull_ratio: .85
      mon_host: ceph-mon
    mon:
      mon_osd_down_out_interval: 600
      mon_osd_min_down_reporters: 4
      mon_clock_drift_allowed: .15
      mon_clock_drift_warn_backoff: 30
      mon_osd_report_timeout: 300
    osd:
      journal_size: 100
      osd_mkfs_type: xfs
      osd_mkfs_options_xfs: -f -i size=2048
      osd_mon_heartbeat_interval: 30
      osd_max_object_name_len: 256
      #crush
      osd_pool_default_crush_rule: 0
      osd_crush_update_on_start: true
      #backend
      osd_objectstore: filestore
      #performance tuning
      filestore_merge_threshold: 40
      filestore_split_multiple: 8
      osd_op_threads: 8
      filestore_op_threads: 8
      filestore_max_sync_interval: 5
      osd_max_scrubs: 1
      #recovery tuning
      osd_recovery_max_active: 5
      osd_max_backfills: 2
      osd_recovery_op_priority: 2
      osd_client_op_priority: 63
      osd_recovery_max_chunk: 1048576
      osd_recovery_threads: 1
      #ports
      ms_bind_port_min: 6800
      ms_bind_port_max: 7100
    client:
      rbd_cache_enabled: true
      rbd_cache_writethrough_until_flush: true
      rbd_default_features: "1"
    mds:
      mds_cache_size: 100000

resources:
  osd:
    requests:
      memory: "512Mi"
      cpu: "1000m"
    limits:
      memory: "1024Mi"
      cpu: "2000m"
  mds:
    replicas: 1
    requests:
      memory: "10Mi"
      cpu: "250m"
    limits:
      memory: "50Mi"
      cpu: "500m"
  mon:
    replicas: 3
    requests:
      memory: "50Mi"
      cpu: "1000m"
    limits:
      memory: "100Mi"
      cpu: "2000m"
  mon_check:
    requests:
      memory: "5Mi"
      cpu: "250m"
    limits:
      memory: "50Mi"
      cpu: "500m"
  rgw:
    replicas: 1
    requests:
      memory: "50Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  exporter:
    requests:
      memory: "10Mi"
      cpu: "250m"
    limits:
      memory: "50Mi"
      cpu: "500m"

storageclass:
  name: general
  pool: rbd
  admin_id: admin
  admin_secret_name: pvc-ceph-conf-combined-storageclass
  user_id: admin
  user_secret_name: pvc-ceph-client-key
